{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPOBmbM0RIge7kOXZO4bo0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryo-nakajima/the_effect_test/blob/master/uth_bert_medpeer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 必須: ライブラリのインストール"
      ],
      "metadata": {
        "id": "vt5PQIT2yalk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers  # Hugging Face Transformersライブラリ\n",
        "!pip install mecab-python3  # MeCabのPythonバインディング\n"
      ],
      "metadata": {
        "id": "18C-kMLFyfVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UTH-BERTモデルのダウンロードとセットアップ"
      ],
      "metadata": {
        "id": "Q6Xc68a_ya3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ai-health.m.u-tokyo.ac.jp/labweb/dl/uth_bert/UTH_BERT_BASE_512_MC_BPE_WWM_V25000_352K_pytorch.zip\n",
        "!unzip UTH_BERT_BASE_512_MC_BPE_WWM_V25000_352K_pytorch.zip\n",
        "!rm UTH_BERT_BASE_512_MC_BPE_WWM_V25000_352K_pytorch.zip"
      ],
      "metadata": {
        "id": "8M21rbIQypPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MeCabとNEologdのセットアップ"
      ],
      "metadata": {
        "id": "oYzWbA88yY0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install mecab libmecab-dev mecab-ipadic-utf8 file\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -a -y"
      ],
      "metadata": {
        "id": "nLJ8IWO9yp4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " MeCabの初期化"
      ],
      "metadata": {
        "id": "waYV5_W_yz6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import MeCab\n",
        "import subprocess\n",
        "\n",
        "# NEologdのパスを取得\n",
        "cmd = 'echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "neologd_dic_dir_path = subprocess.check_output(cmd, shell=True).decode('utf-8').strip()\n",
        "\n",
        "# MeCabを初期化\n",
        "mecab = MeCab.Tagger(f\"-d {neologd_dic_dir_path}\")\n"
      ],
      "metadata": {
        "id": "71Muxol3y16m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "万病辞書"
      ],
      "metadata": {
        "id": "28pOVHvjy4P7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://sociocom.jp/~data/2018-manbyo/data/MANBYO_201907_Dic-utf8.dic\n"
      ],
      "metadata": {
        "id": "_si1J-B6y-Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "トークナイザ関数とモデルロード"
      ],
      "metadata": {
        "id": "QEy3Ft5hzAFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# モデルのパスを指定\n",
        "model_path = \"./UTH_BERT_BASE_512_MC_BPE_WWM_V25000_352K\"\n",
        "\n",
        "# トークナイザとモデルをロード\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertModel.from_pretrained(model_path)\n"
      ],
      "metadata": {
        "id": "490ORmIUzB_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "実行するコード部分"
      ],
      "metadata": {
        "id": "CvNlXYzszDUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_with_mecab(text):\n",
        "    text = mecab.parse(text)\n",
        "    return text.splitlines()\n",
        "\n",
        "def get_cls_embedding(text, model, tokenizer):\n",
        "    tokens = tokenize_with_mecab(text)\n",
        "    encoded = tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "    return cls_embedding.squeeze(0)\n",
        "\n",
        "def calculate_cosine_similarity(embedding1, embedding2):\n",
        "    similarity = F.cosine_similarity(embedding1, embedding2, dim=0)\n",
        "    return similarity.item()\n"
      ],
      "metadata": {
        "id": "mdpKgZpUzFQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "類似性の計算"
      ],
      "metadata": {
        "id": "ax5tIAO2zRgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# モデルのパス\n",
        "model_path = \"./UTH_BERT_BASE_512_MC_BPE_WWM_V25000_352K\"\n",
        "\n",
        "# トークナイザとモデルをロード\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertModel.from_pretrained(model_path)\n",
        "\n",
        "# CSVファイルを読み込む\n",
        "file_path = \"./data/comments_physicians.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# コメントの特徴ベクトルを取得する関数\n",
        "def get_cls_embedding(text, model, tokenizer):\n",
        "    # MeCabで形態素解析\n",
        "    import MeCab\n",
        "    mecab = MeCab.Tagger(\"-Owakati\")\n",
        "    tokens = mecab.parse(text).strip().split()\n",
        "\n",
        "    # トークナイザでトークナイズ\n",
        "    encoded = tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\")\n",
        "\n",
        "    # モデルを推論モードに設定して推論\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded)\n",
        "\n",
        "    # [CLS]トークンの埋め込みを取得\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # CLSトークン: 位置0\n",
        "    return cls_embedding.squeeze(0)  # ベクトルの形状を整える\n",
        "\n",
        "# コサイン類似度を計算する関数\n",
        "def calculate_cosine_similarity(embedding1, embedding2):\n",
        "    similarity = F.cosine_similarity(embedding1, embedding2, dim=0)\n",
        "    return similarity.item()\n",
        "\n",
        "# 任意の行を指定して類似度を計算\n",
        "row1, row2 = 0, 1  # 計算したい2つの行のインデックスを指定\n",
        "comment1 = df.loc[row1, \"comment\"]\n",
        "comment2 = df.loc[row2, \"comment\"]\n",
        "\n",
        "# コメントの埋め込みを取得\n",
        "embedding1 = get_cls_embedding(comment1, model, tokenizer)\n",
        "embedding2 = get_cls_embedding(comment2, model, tokenizer)\n",
        "\n",
        "# 類似度を計算\n",
        "similarity = calculate_cosine_similarity(embedding1, embedding2)\n",
        "\n",
        "# 結果を表示\n",
        "print(f\"Similarity between row {row1} and row {row2}: {similarity}\")\n"
      ],
      "metadata": {
        "id": "s5kijKDyzUDM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}